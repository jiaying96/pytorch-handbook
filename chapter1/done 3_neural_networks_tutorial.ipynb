{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "该层的结构[6, 1, 5, 5]\n",
    "该层的结构[6]\n",
    "该层的结构[16, 6, 5, 5]\n",
    "该层的结构[16]\n",
    "该层的结构[120, 400]\n",
    "该层的结构[120]\n",
    "该层的结构[84, 120]\n",
    "该层的结构[84]\n",
    "该层的结构[10, 84]\n",
    "该层的结构[10]\n",
    "总参数和61706"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Neural Networks\n",
    "===============\n",
    "\n",
    "使用torch.nn包来构建神经网络。\n",
    "\n",
    "上一讲已经讲过了``autograd``，``nn``包依赖``autograd``包来定义模型并求导。\n",
    "一个``nn.Module``包含各个层和一个``forward(input)``方法，该方法返回``output``。\n",
    "\n",
    "\n",
    "\n",
    "例如：\n",
    "\n",
    "![](https://pytorch.org/tutorials/_images/mnist.png)\n",
    "\n",
    "它是一个简单的前馈神经网络，它接受一个输入，然后一层接着一层地传递，最后输出计算的结果。\n",
    "\n",
    "神经网络的典型训练过程如下：\n",
    "\n",
    "1. 定义包含一些可学习的参数(或者叫权重)神经网络模型； \n",
    "2. 在数据集上迭代； \n",
    "3. 通过神经网络处理输入； \n",
    "4. 计算损失(输出结果和正确值的差值大小)；\n",
    "5. 将梯度反向传播回网络的参数； \n",
    "6. 更新网络的参数，主要使用如下简单的更新原则： \n",
    "``weight = weight - learning_rate * gradient``\n",
    "\n",
    "  \n",
    "\n",
    "定义网络\n",
    "------------------\n",
    "\n",
    "开始定义一个网络：\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# -*-conding:UTF-8 -*-\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        #初始化\n",
    "        # 用于net = Net() \n",
    "        # 复制并使用Net的父类的初始化方法，即先运行nn.Module的初始化函数\n",
    "        super(Net, self).__init__() \n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        ''' \n",
    "        参数\n",
    "        (self, in_channels, out_channels, kernel_size, stride=1,\n",
    "                 padding=0, dilation=1, groups=1, bias=True)\n",
    "        ''' \n",
    "        #定义conv1 卷积函数 输入特征图为1（灰度图）   输出为6个特征图  卷积核5*5\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        #全链接函数为线性函数  y = Wx + b 将16*5*5个节点连接到120个节点上\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    #定义前行传播函数 该函数必须定义  一旦定义成果，向后传播函数也会自动生成    \n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        # 输入x经过卷积conv1后，经过激活函数relu，使用2*2窗口进行最大池化，然后更新到x\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        \n",
    "        # add\n",
    "        print(\"x size before\")\n",
    "        print(x.size())\n",
    "        #x size before\n",
    "        #torch.Size([1, 16, 5, 5])\n",
    "        #  end add\n",
    "        \n",
    "        # view函数将张量x更新成一维的向量形式，总特征数不变，为接下来的全连接做准备\n",
    "        #将一个多行的Tensor,拼接成一行\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        \n",
    "        # add\n",
    "        print(\"self.num_flat_features(x)\")\n",
    "        print(self.num_flat_features(x))\n",
    "        #self.num_flat_features(x)\n",
    "        #400\n",
    "        print(\"x size after\")\n",
    "        print(x.size())\n",
    "        #x size after\n",
    "        #torch.Size([1, 400])\n",
    "        # end add\n",
    "        \n",
    "        #经过全连接函数后 再经过relu激活函数，然后更新x\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        #经过全连接函数后更新x\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    #计算张量的总特征数  [1, 16, 5, 5] 特征数为16*5**5\n",
    "    def num_flat_features(self, x):\n",
    "        print(\"x.size()\")\n",
    "        print(x.size())\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        print(\"size = x.size()[1:]   size为\")\n",
    "        print(size)\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            print('s')\n",
    "            print(s)\n",
    "            num_features *= s\n",
    "            print(\" num_features *= s  后 num_features  \")\n",
    "            print(num_features)\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net() \n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在模型中必须要定义 ``forward`` 函数，``backward``\n",
    "函数（用来计算梯度）会被``autograd``自动创建。\n",
    "可以在 ``forward`` 函数中使用任何针对 Tensor 的操作。\n",
    "\n",
    " ``net.parameters()``返回可被学习的参数（权重）列表和值\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 5, 5])\n",
      "该层的结构[6, 1, 5, 5]\n",
      "参数和：150\n",
      "该层的结构[6]\n",
      "参数和：6\n",
      "该层的结构[16, 6, 5, 5]\n",
      "参数和：2400\n",
      "该层的结构[16]\n",
      "参数和：16\n",
      "该层的结构[120, 400]\n",
      "参数和：48000\n",
      "该层的结构[120]\n",
      "参数和：120\n",
      "该层的结构[84, 120]\n",
      "参数和：10080\n",
      "该层的结构[84]\n",
      "参数和：84\n",
      "该层的结构[10, 84]\n",
      "参数和：840\n",
      "该层的结构[10]\n",
      "参数和：10\n",
      "总参数和61706\n"
     ]
    }
   ],
   "source": [
    "# net.parameters()返回可被学习的参数（权重）列表和值\n",
    "#需要训练的参数的数量\n",
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())  # conv1's .weight\n",
    "\n",
    "k=0\n",
    "for i in params:\n",
    "    l=1\n",
    "    print(\"该层的结构\"+str(list(i.size())))\n",
    "    for j in i.size():\n",
    "        l*=j\n",
    "    print(\"参数和：\"+str(l))\n",
    "    k=k+l\n",
    "print(\"总参数和\"+str(k))\n",
    "\n",
    "# Net(\n",
    "#   (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
    "#   (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
    "#   (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
    "#   (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
    "#   (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试随机输入32×32。\n",
    "注：这个网络（LeNet）期望的输入大小是32×32，如果使用MNIST数据集来训练这个网络，请把图片大小重新调整到32×32。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x size before\n",
      "torch.Size([1, 16, 5, 5])\n",
      "x.size()\n",
      "torch.Size([1, 16, 5, 5])\n",
      "size = x.size()[1:]   size为\n",
      "torch.Size([16, 5, 5])\n",
      "s\n",
      "16\n",
      " num_features *= s  后 num_features  \n",
      "16\n",
      "s\n",
      "5\n",
      " num_features *= s  后 num_features  \n",
      "80\n",
      "s\n",
      "5\n",
      " num_features *= s  后 num_features  \n",
      "400\n",
      "self.num_flat_features(x)\n",
      "x.size()\n",
      "torch.Size([1, 400])\n",
      "size = x.size()[1:]   size为\n",
      "torch.Size([400])\n",
      "s\n",
      "400\n",
      " num_features *= s  后 num_features  \n",
      "400\n",
      "400\n",
      "x size after\n",
      "torch.Size([1, 400])\n",
      "10\n",
      "torch.Size([6, 1, 5, 5])\n",
      "该层的结构[6, 1, 5, 5]\n",
      "该层的结构[6]\n",
      "该层的结构[16, 6, 5, 5]\n",
      "该层的结构[16]\n",
      "该层的结构[120, 400]\n",
      "该层的结构[120]\n",
      "该层的结构[84, 120]\n",
      "该层的结构[84]\n",
      "该层的结构[10, 84]\n",
      "该层的结构[10]\n",
      "总参数和61706\n",
      "out:\n",
      "tensor([[ 0.1764,  0.0688,  0.0216,  0.0414,  0.1376,  0.0054, -0.0468,  0.0038,\n",
      "          0.0777,  0.0253]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 32, 32)\n",
    "out = net(input)\n",
    "# net.parameters()返回可被学习的参数（权重）列表和值\n",
    "#需要训练的参数的数量\n",
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())  # conv1's .weight\n",
    "\n",
    "k=0\n",
    "for i in params:\n",
    "    l=1\n",
    "    print(\"该层的结构\"+str(list(i.size())))\n",
    "    for j in i.size():\n",
    "        l*=j\n",
    "    k=k+l\n",
    "print(\"总参数和\"+str(k))\n",
    "\n",
    "\n",
    "print(\"out:\")\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将所有参数的梯度缓存清零，然后进行随机梯度的的反向传播：\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad() #将所有参数的梯度缓存清零\n",
    "out.backward(torch.randn(1, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><h4>Note</h4><p>``torch.nn`` 只支持小批量输入。整个 ``torch.nn``\n",
    "包都只支持小批量样本，而不支持单个样本。\n",
    "\n",
    "    例如，``nn.Conv2d`` 接受一个4维的张量，\n",
    "    ``每一维分别是sSamples * nChannels * Height * Width（样本数*通道数*高*宽）``。\n",
    "\n",
    "    如果你有单个样本，只需使用 ``input.unsqueeze(0)`` 来添加其它的维数</p></div>\n",
    "\n",
    "在继续之前，我们回顾一下到目前为止用到的类。\n",
    "\n",
    "**回顾:**\n",
    "  -  ``torch.Tensor``：一个用过自动调用 ``backward()``实现支持自动梯度计算的 *多维数组* ，\n",
    "      并且保存关于这个向量的*梯度* w.r.t.\n",
    "  -  ``nn.Module``：神经网络模块。封装参数、移动到GPU上运行、导出、加载等。\n",
    "  -  ``nn.Parameter``：一种变量，当把它赋值给一个``Module``时，被 *自动* 地注册为一个参数。\n",
    "  -  ``autograd.Function``：实现一个自动求导操作的前向和反向定义，每个变量操作至少创建一个函数节点，每一个``Tensor``的操作都回创建一个接到创建``Tensor``和 *编码其历史* 的函数的``Function``节点。\n",
    "\n",
    "**重点如下：**\n",
    "  -  定义一个网络\n",
    "  -  处理输入，调用backword\n",
    "\n",
    "**还剩：**\n",
    "  -  计算损失\n",
    "  -  更新网络权重\n",
    "\n",
    "损失函数\n",
    "-------------\n",
    "一个损失函数接受一对 (output, target) 作为输入，计算一个值来估计网络的输出和目标值相差多少。\n",
    "\n",
    "***译者注：output为网络的输出，target为实际值***\n",
    "\n",
    "nn包中有很多不同的[损失函数](https://pytorch.org/docs/nn.html#loss-functions)。\n",
    "``nn.MSELoss``是一个比较简单的损失函数，它计算输出和目标间的**均方误差**，\n",
    "例如：\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7.8644e-01, 4.5912e-41, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]])\n",
      "tensor([[7.8644e-01, 4.5912e-41, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]])\n",
      "d  size\n",
      "torch.Size([3, 4, 35])\n",
      "e  size\n",
      "torch.Size([4, 21, 5])\n"
     ]
    }
   ],
   "source": [
    "#将一个多行的Tensor,拼接成一行\n",
    "import torch\n",
    " \n",
    "a = torch.Tensor(2,3)\n",
    "print(a)\n",
    "# tensor([[0.0000, 0.0000, 0.0000],\n",
    "#        [0.0000, 0.0000, 0.0000]])\n",
    " \n",
    "print(a.view(1,-1))  #其中参数-1表示剩下的值的个数一起构成一个维度\n",
    "# tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]])\n",
    "#如上例中，第一个参数1将第一个维度的大小设定成1，\n",
    "#后一个-1就是说第二个维度的大小=元素总数目/第一个维度的大小，此例中为2*3/1=6.\n",
    "\n",
    "aa=torch.randn(3,4,5,7)\n",
    "d = aa.view(aa.size(0),aa.size(1),-1)  #等价于d = aa.view(3,4,-1)\n",
    "print(\"d  size\")\n",
    "print(d.size())\n",
    "e=aa.view(4,-1,5)\n",
    "print(\"e  size\")\n",
    "print(e.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x size before\n",
      "torch.Size([1, 16, 5, 5])\n",
      "x.size()\n",
      "torch.Size([1, 16, 5, 5])\n",
      "size = x.size()[1:]   size为\n",
      "torch.Size([16, 5, 5])\n",
      "s\n",
      "16\n",
      " num_features *= s  后 num_features  \n",
      "16\n",
      "s\n",
      "5\n",
      " num_features *= s  后 num_features  \n",
      "80\n",
      "s\n",
      "5\n",
      " num_features *= s  后 num_features  \n",
      "400\n",
      "self.num_flat_features(x)\n",
      "x.size()\n",
      "torch.Size([1, 400])\n",
      "size = x.size()[1:]   size为\n",
      "torch.Size([400])\n",
      "s\n",
      "400\n",
      " num_features *= s  后 num_features  \n",
      "400\n",
      "400\n",
      "x size after\n",
      "torch.Size([1, 400])\n",
      "target 前\n",
      "tensor([-0.6149,  0.6415, -0.9337,  0.5052, -1.5060,  0.6875, -0.7407,  0.1086,\n",
      "         0.6976, -0.4932])\n",
      "target 后\n",
      "tensor([[-0.6149,  0.6415, -0.9337,  0.5052, -1.5060,  0.6875, -0.7407,  0.1086,\n",
      "          0.6976, -0.4932]])\n",
      "loss\n",
      "tensor(0.6377, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "output = net(input)\n",
    "target = torch.randn(10)  # 随机值作为样例\n",
    "print(\"target 前\")\n",
    "print(target)\n",
    "#将一个多行的Tensor,拼接成一行\n",
    "#其中参数-1表示剩下的值的个数一起构成一个维度\n",
    "target = target.view(1, -1)  # 使target和output的shape相同\n",
    "print(\"target 后\")\n",
    "print(target)\n",
    "criterion = nn.MSELoss() #均方损失函数\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(\"loss\")\n",
    "print(loss)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if you follow ``loss`` in the backward direction, using its\n",
    "``.grad_fn`` attribute, you will see a graph of computations that looks\n",
    "like this:\n",
    "\n",
    "::\n",
    "\n",
    "    input -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d\n",
    "          -> view -> linear -> relu -> linear -> relu -> linear\n",
    "          -> MSELoss\n",
    "          -> loss\n",
    "\n",
    "So, when we call ``loss.backward()``, the whole graph is differentiated\n",
    "w.r.t. the loss, and all Tensors in the graph that has ``requires_grad=True``\n",
    "will have their ``.grad`` Tensor accumulated with the gradient.\n",
    "\n",
    "For illustration, let us follow a few steps backward:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward object at 0x00000183A538DDD8>\n",
      "<AddmmBackward object at 0x00000183A5380C88>\n",
      "<AccumulateGrad object at 0x00000183A538DDD8>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn)  # MSELoss  均方误差  L2\n",
    "print(loss.grad_fn.next_functions[0][0])  # Linear\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "反向传播\n",
    "--------\n",
    "调用loss.backward()获得反向传播的误差。\n",
    "\n",
    "但是在调用前需要清除已存在的梯度，否则梯度将被累加到已存在的梯度。\n",
    "\n",
    "现在，我们将调用loss.backward()，并查看conv1层的偏差（bias）项在反向传播前后的梯度。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "conv1.bias.grad after backward\n",
      "tensor([-0.0031,  0.0059,  0.0022, -0.0004, -0.0074,  0.0073])\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()     # 清除梯度\n",
    "\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如何使用损失函数\n",
    "\n",
    "**稍后阅读：**\n",
    "\n",
    "  `nn`包，包含了各种用来构成深度神经网络构建块的模块和损失函数，完整的文档请查看[here](https://pytorch.org/docs/nn)。\n",
    "\n",
    "**剩下的最后一件事:**\n",
    "\n",
    "  - 新网络的权重\n",
    "\n",
    "更新权重\n",
    "------------------\n",
    "在实践中最简单的权重更新规则是随机梯度下降（SGD）：\n",
    "\n",
    "     ``weight = weight - learning_rate * gradient``\n",
    "\n",
    "我们可以使用简单的Python代码实现这个规则：\n",
    "\n",
    "```python\n",
    "\n",
    "    learning_rate = 0.01\n",
    "    for f in net.parameters():\n",
    "        f.data.sub_(f.grad.data * learning_rate)\n",
    "```\n",
    "但是当使用神经网络是想要使用各种不同的更新规则时，比如SGD、Nesterov-SGD、Adam、RMSPROP等，PyTorch中构建了一个包``torch.optim``实现了所有的这些规则。\n",
    "使用它们非常简单：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x size before\n",
      "torch.Size([1, 16, 5, 5])\n",
      "x.size()\n",
      "torch.Size([1, 16, 5, 5])\n",
      "size = x.size()[1:]   size为\n",
      "torch.Size([16, 5, 5])\n",
      "s\n",
      "16\n",
      " num_features *= s  后 num_features  \n",
      "16\n",
      "s\n",
      "5\n",
      " num_features *= s  后 num_features  \n",
      "80\n",
      "s\n",
      "5\n",
      " num_features *= s  后 num_features  \n",
      "400\n",
      "self.num_flat_features(x)\n",
      "x.size()\n",
      "torch.Size([1, 400])\n",
      "size = x.size()[1:]   size为\n",
      "torch.Size([400])\n",
      "s\n",
      "400\n",
      " num_features *= s  后 num_features  \n",
      "400\n",
      "400\n",
      "x size after\n",
      "torch.Size([1, 400])\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# in your training loop:\n",
    "optimizer.zero_grad()   # zero the gradient buffers\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step()    # Does the update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".. Note::\n",
    "    \n",
    "      Observe how gradient buffers had to be manually set to zero using\n",
    "      ``optimizer.zero_grad()``. This is because gradients are accumulated\n",
    "      as explained in `Backprop`_ section.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch_exericise"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
